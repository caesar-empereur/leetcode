# leetcode
算法刷题

## 20G的文件，每行存放1个URL，请用1G的内存计算出重复次数最多的前100个URL

- 解题思路：位图过滤不重复，分治法，HashMap，小顶堆筛选
    
    - 1 先用位图过滤不重复的数据
        ```
        为什么要过滤不重复的数据，因为不重复的数据在后面根本不用计算，
        这样筛选掉不重复的是为了减少不必要的计算量
        ```
        - 先构建一个长度为 20亿bit的位图，需要内存为 0.25 GB
        - 把 20亿个URL(640GB)的数据依次根据位图长度算出位图下标
        - 如果对应下标被设置为1，说明数据重复，将重复数据输出到另一个文件
        - 如果下标是 0，说明当前数据不存在重复，将对应下标设置为 1
        - 20亿的数据经过处理之后输出的文件结果，数量为 X，大小范围为 1-10亿
        - 如果结果文件小于 100 万个(0.64GB), 则不用分治处理了，直接放到 map 一次处理完
        - 如果结果文件大于 100 万个(0.64GB), 则分成 Y=X/100万 份，例如1亿个，则分成100份
    - 2 将上一步的结果集 分治处理 
        - 将大文件的URL依次对 Y 哈希取模算出是在 Y 份文件的第几份
        - 相同的URL肯定会分到同一份文件
    - 3 将每一份文件的数据放到 HashMap 中处理
        ```
        在单个 Map 里面能处理的最大数据为 100 万个 (0.64 GB)
        因此在分治处理的时候要把每一份数据切割到能放到内存处理,因此每份数据最大 100 万个 (0.64 GB)
        ```
        - 将每一份文件的结果放到 HashMap 中，key是URL，value是出现次数
        - 每一份文件的URL放到 Map 的方式为先判断是否存在 key 相同的URL,存在则value加1，否则把url put 进去
    - 4 构建一个容量为 1000 的小顶堆，堆的关键字的比较器是 Map 的value 次数大小比较
        - 每生成一个Map,就将 Map 遍历，如果小顶堆的元素数量小于1000个，则将 Map 的key放到堆中
        - 如果小顶堆的元素数量等于 1000，则与堆顶的元素的次数比较，比堆顶大，则将堆顶替换为新的key
        - 每一份文件拿到 Map 中处理完之后，将map清空，继续将下一份文件拿进来用相同方式处理
        - 这样每一份文件用一个map处理之后，都是通过遍历map与小顶堆比较，通过不断与堆的比较替换
        - 最终所有文件处理完了之后，容量为 1000 的小顶堆的结果输出，就是出现次数 前 1000 的URL
